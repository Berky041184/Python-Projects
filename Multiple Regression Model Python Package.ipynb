{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46590c3a",
   "metadata": {},
   "source": [
    "# Multiple Regression Python Code Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda8cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Purpose: The code below is the proposed model for the dependent variables based on the final candidate variables from \n",
    "# stage 3 - Candidate models.  The code will generate the full model diagnostic tests, backtesting results and graphing \n",
    "# the predicted with actuals in an excel output workbook.  This code comes up with the strongest candidate models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff7e0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Up Libraries\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import numpy as np\n",
    "import statsmodels.api as linear_model\n",
    "#from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import scipy.stats as stats\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "import matplotlib.dates as mdates\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "import seaborn as sns\n",
    "import xlsxwriter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from numpy import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59be953b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>3-month Treasury rate</th>\n",
       "      <th>5-year Treasury yield</th>\n",
       "      <th>10-year Treasury yield</th>\n",
       "      <th>House Price Index (Level)</th>\n",
       "      <th>30Y Current Coupon UMBS/FNMA Yield</th>\n",
       "      <th>30Y10Y_MBSOAS_TY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7/1/2009</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>139.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/1/2009</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>139.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2010</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>140.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/1/2010</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>140.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7/1/2010</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>139.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10/1/2010</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>136.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/1/2011</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>135.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>18.08130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4/1/2011</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>134.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>21.47880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7/1/2011</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>133.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>32.61530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10/1/2011</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>134.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>37.57190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1/1/2012</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>134.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>28.55870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4/1/2012</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>135.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>27.87350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7/1/2012</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>139.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>15.63040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10/1/2012</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>141.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-13.95950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1/1/2013</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>144.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.09720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4/1/2013</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>148.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>12.80500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7/1/2013</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>152.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>35.28420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10/1/2013</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>156.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>20.14430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1/1/2014</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>159.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>13.67310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4/1/2014</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>161.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>17.69770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7/1/2014</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>162.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>17.05320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10/1/2014</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>164.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.33960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.81610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4/1/2015</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>9.42510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7/1/2015</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>171.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>10.67690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10/1/2015</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>173.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>9.04580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>175.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>17.45220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4/1/2016</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>178.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>22.89060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7/1/2016</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>180.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>17.12570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10/1/2016</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>182.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.41746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>185.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>9.54164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4/1/2017</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>188.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.21230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7/1/2017</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>190.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.68020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10/1/2017</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>193.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.01862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>196.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>13.01150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4/1/2018</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>199.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>22.83000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7/1/2018</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>202.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>20.88740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10/1/2018</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>204.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.26280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1/1/2019</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>205.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>22.17800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4/1/2019</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>207.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>32.02820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7/1/2019</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>209.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.48420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10/1/2019</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>211.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>41.86950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1/1/2020</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>215.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>10.12940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4/1/2020</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>217.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>28.01090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>7/1/2020</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>219.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-25.44510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10/1/2020</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>226.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>13.27660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1/1/2021</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>235.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-1.74740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4/1/2021</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>243.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-33.27440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>7/1/2021</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>254.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-15.01690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>10/1/2021</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>266.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-20.65740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1/1/2022</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>277.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>13.28500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4/1/2022</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>290.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>34.03620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>7/1/2022</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>297.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>9.20502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>10/1/2022</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>297.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>55.20630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1/1/2023</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>299.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>11.66230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        month  Unemployment rate  3-month Treasury rate  \\\n",
       "0    7/1/2009                9.3                    0.2   \n",
       "1   10/1/2009                9.6                    0.2   \n",
       "2    1/1/2010                9.9                    0.1   \n",
       "3    4/1/2010                9.8                    0.1   \n",
       "4    7/1/2010                9.6                    0.1   \n",
       "5   10/1/2010                9.5                    0.2   \n",
       "6    1/1/2011                9.5                    0.1   \n",
       "7    4/1/2011                9.0                    0.1   \n",
       "8    7/1/2011                9.1                    0.0   \n",
       "9   10/1/2011                9.0                    0.0   \n",
       "10   1/1/2012                8.6                    0.0   \n",
       "11   4/1/2012                8.3                    0.1   \n",
       "12   7/1/2012                8.2                    0.1   \n",
       "13  10/1/2012                8.0                    0.1   \n",
       "14   1/1/2013                7.8                    0.1   \n",
       "15   4/1/2013                7.7                    0.1   \n",
       "16   7/1/2013                7.5                    0.1   \n",
       "17  10/1/2013                7.2                    0.0   \n",
       "18   1/1/2014                6.9                    0.1   \n",
       "19   4/1/2014                6.7                    0.0   \n",
       "20   7/1/2014                6.2                    0.0   \n",
       "21  10/1/2014                6.1                    0.0   \n",
       "22   1/1/2015                5.7                    0.0   \n",
       "23   4/1/2015                5.5                    0.0   \n",
       "24   7/1/2015                5.4                    0.0   \n",
       "25  10/1/2015                5.1                    0.0   \n",
       "26   1/1/2016                5.0                    0.1   \n",
       "27   4/1/2016                4.9                    0.3   \n",
       "28   7/1/2016                4.9                    0.3   \n",
       "29  10/1/2016                4.9                    0.3   \n",
       "30   1/1/2017                4.8                    0.4   \n",
       "31   4/1/2017                4.6                    0.6   \n",
       "32   7/1/2017                4.4                    0.9   \n",
       "33  10/1/2017                4.3                    1.0   \n",
       "34   1/1/2018                4.2                    1.2   \n",
       "35   4/1/2018                4.0                    1.6   \n",
       "36   7/1/2018                3.9                    1.8   \n",
       "37  10/1/2018                3.8                    2.0   \n",
       "38   1/1/2019                3.8                    2.3   \n",
       "39   4/1/2019                3.9                    2.4   \n",
       "40   7/1/2019                3.6                    2.3   \n",
       "41  10/1/2019                3.6                    2.0   \n",
       "42   1/1/2020                3.6                    1.6   \n",
       "43   4/1/2020                3.8                    1.1   \n",
       "44   7/1/2020               13.0                    0.1   \n",
       "45  10/1/2020                8.8                    0.1   \n",
       "46   1/1/2021                6.8                    0.1   \n",
       "47   4/1/2021                6.2                    0.1   \n",
       "48   7/1/2021                5.9                    0.0   \n",
       "49  10/1/2021                5.1                    0.0   \n",
       "50   1/1/2022                4.2                    0.1   \n",
       "51   4/1/2022                3.8                    0.3   \n",
       "52   7/1/2022                3.6                    1.1   \n",
       "53  10/1/2022                3.6                    2.7   \n",
       "54   1/1/2023                3.6                    4.0   \n",
       "\n",
       "    5-year Treasury yield  10-year Treasury yield  House Price Index (Level)  \\\n",
       "0                     2.3                     3.7                      139.2   \n",
       "1                     2.5                     3.8                      139.7   \n",
       "2                     2.3                     3.7                      140.2   \n",
       "3                     2.4                     3.9                      140.2   \n",
       "4                     2.3                     3.6                      139.3   \n",
       "5                     1.6                     2.9                      136.7   \n",
       "6                     1.5                     3.0                      135.4   \n",
       "7                     2.1                     3.5                      134.1   \n",
       "8                     1.8                     3.3                      133.7   \n",
       "9                     1.1                     2.5                      134.3   \n",
       "10                    1.0                     2.1                      134.3   \n",
       "11                    0.9                     2.1                      135.8   \n",
       "12                    0.8                     1.8                      139.0   \n",
       "13                    0.7                     1.6                      141.7   \n",
       "14                    0.7                     1.7                      144.7   \n",
       "15                    0.8                     1.9                      148.4   \n",
       "16                    0.9                     2.0                      152.4   \n",
       "17                    1.5                     2.7                      156.1   \n",
       "18                    1.4                     2.8                      159.2   \n",
       "19                    1.6                     2.8                      161.2   \n",
       "20                    1.7                     2.7                      162.3   \n",
       "21                    1.7                     2.5                      164.4   \n",
       "22                    1.6                     2.3                      167.0   \n",
       "23                    1.5                     2.0                      169.0   \n",
       "24                    1.5                     2.2                      171.0   \n",
       "25                    1.6                     2.3                      173.5   \n",
       "26                    1.6                     2.2                      175.9   \n",
       "27                    1.4                     2.0                      178.1   \n",
       "28                    1.3                     1.8                      180.1   \n",
       "29                    1.2                     1.6                      182.6   \n",
       "30                    1.7                     2.2                      185.5   \n",
       "31                    2.0                     2.5                      188.0   \n",
       "32                    1.8                     2.3                      190.6   \n",
       "33                    1.8                     2.3                      193.6   \n",
       "34                    2.1                     2.4                      196.7   \n",
       "35                    2.5                     2.8                      199.7   \n",
       "36                    2.8                     2.9                      202.0   \n",
       "37                    2.8                     2.9                      204.0   \n",
       "38                    2.9                     3.0                      205.9   \n",
       "39                    2.5                     2.7                      207.5   \n",
       "40                    2.1                     2.4                      209.5   \n",
       "41                    1.7                     1.8                      211.9   \n",
       "42                    1.6                     1.8                      215.2   \n",
       "43                    1.2                     1.4                      217.8   \n",
       "44                    0.4                     0.7                      219.9   \n",
       "45                    0.3                     0.6                      226.9   \n",
       "46                    0.4                     0.9                      235.3   \n",
       "47                    0.6                     1.4                      243.0   \n",
       "48                    0.8                     1.6                      254.6   \n",
       "49                    0.8                     1.4                      266.3   \n",
       "50                    1.2                     1.6                      277.3   \n",
       "51                    1.9                     2.0                      290.3   \n",
       "52                    3.0                     3.0                      297.5   \n",
       "53                    3.3                     3.2                      297.6   \n",
       "54                    4.1                     3.9                      299.8   \n",
       "\n",
       "    30Y Current Coupon UMBS/FNMA Yield  30Y10Y_MBSOAS_TY  \n",
       "0                                  4.4           0.00000  \n",
       "1                                  4.3           0.00000  \n",
       "2                                  4.4           0.00000  \n",
       "3                                  4.4           0.00000  \n",
       "4                                  3.5           0.00000  \n",
       "5                                  3.4           0.00000  \n",
       "6                                  4.2          18.08130  \n",
       "7                                  4.1          21.47880  \n",
       "8                                  3.8          32.61530  \n",
       "9                                  3.3          37.57190  \n",
       "10                                 2.7          28.55870  \n",
       "11                                 2.8          27.87350  \n",
       "12                                 2.3          15.63040  \n",
       "13                                 2.1         -13.95950  \n",
       "14                                 2.6           7.09720  \n",
       "15                                 2.4          12.80500  \n",
       "16                                 3.4          35.28420  \n",
       "17                                 3.2          20.14430  \n",
       "18                                 3.3          13.67310  \n",
       "19                                 3.3          17.69770  \n",
       "20                                 3.3          17.05320  \n",
       "21                                 3.0          12.33960  \n",
       "22                                 2.5           8.81610  \n",
       "23                                 2.7           9.42510  \n",
       "24                                 2.9          10.67690  \n",
       "25                                 2.8           9.04580  \n",
       "26                                 2.6          17.45220  \n",
       "27                                 2.6          22.89060  \n",
       "28                                 2.2          17.12570  \n",
       "29                                 2.5           5.41746  \n",
       "30                                 3.2           9.54164  \n",
       "31                                 3.0          14.21230  \n",
       "32                                 3.0          13.68020  \n",
       "33                                 3.0           7.01862  \n",
       "34                                 3.3          13.01150  \n",
       "35                                 3.6          22.83000  \n",
       "36                                 3.7          20.88740  \n",
       "37                                 4.0          31.26280  \n",
       "38                                 3.4          22.17800  \n",
       "39                                 3.3          32.02820  \n",
       "40                                 3.0          22.48420  \n",
       "41                                 2.6          41.86950  \n",
       "42                                 2.2          10.12940  \n",
       "43                                 1.5          28.01090  \n",
       "44                                 0.8         -25.44510  \n",
       "45                                 0.7          13.27660  \n",
       "46                                 1.4          -1.74740  \n",
       "47                                 1.8         -33.27440  \n",
       "48                                 1.7         -15.01690  \n",
       "49                                 2.0         -20.65740  \n",
       "50                                 2.5          13.28500  \n",
       "51                                 4.2          34.03620  \n",
       "52                                 3.8           9.20502  \n",
       "53                                 5.9          55.20630  \n",
       "54                                 4.9          11.66230  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import history dataset#\n",
    "Hist_Data =pd.read_csv('Agency_MBS_Data.csv')\n",
    "Hist_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57422931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>3-month Treasury rate</th>\n",
       "      <th>5-year Treasury yield</th>\n",
       "      <th>10-year Treasury yield</th>\n",
       "      <th>House Price Index (Level)</th>\n",
       "      <th>30Y10Y_MBSOAS_TY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2020</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>215.2</td>\n",
       "      <td>10.12940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/1/2020</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>217.8</td>\n",
       "      <td>28.01090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7/1/2020</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>219.9</td>\n",
       "      <td>-25.44510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/1/2020</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>226.9</td>\n",
       "      <td>13.27660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2021</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>235.3</td>\n",
       "      <td>-1.74740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4/1/2021</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>243.0</td>\n",
       "      <td>-33.27440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7/1/2021</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>254.6</td>\n",
       "      <td>-15.01690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10/1/2021</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>266.3</td>\n",
       "      <td>-20.65740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/1/2022</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>277.3</td>\n",
       "      <td>13.28500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4/1/2022</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>290.3</td>\n",
       "      <td>34.03620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7/1/2022</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>297.5</td>\n",
       "      <td>9.20502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10/1/2022</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>297.6</td>\n",
       "      <td>55.20630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1/1/2023</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>299.8</td>\n",
       "      <td>11.66230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4/1/2023</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>301.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7/1/2023</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>302.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10/1/2023</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>304.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1/1/2024</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>305.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4/1/2024</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>307.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7/1/2024</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>308.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10/1/2024</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>310.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1/1/2025</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>312.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4/1/2025</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>313.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7/1/2025</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>315.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10/1/2025</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>316.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1/1/2026</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>318.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4/1/2026</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>319.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        month  Unemployment rate  3-month Treasury rate  \\\n",
       "0    1/1/2020                3.6                    1.6   \n",
       "1    4/1/2020                3.8                    1.1   \n",
       "2    7/1/2020               13.0                    0.1   \n",
       "3   10/1/2020                8.8                    0.1   \n",
       "4    1/1/2021                6.8                    0.1   \n",
       "5    4/1/2021                6.2                    0.1   \n",
       "6    7/1/2021                5.9                    0.0   \n",
       "7   10/1/2021                5.1                    0.0   \n",
       "8    1/1/2022                4.2                    0.1   \n",
       "9    4/1/2022                3.8                    0.3   \n",
       "10   7/1/2022                3.6                    1.1   \n",
       "11  10/1/2022                3.6                    2.7   \n",
       "12   1/1/2023                3.6                    4.0   \n",
       "13   4/1/2023                3.9                    4.7   \n",
       "14   7/1/2023                4.3                    4.8   \n",
       "15  10/1/2023                4.6                    4.6   \n",
       "16   1/1/2024                4.8                    4.4   \n",
       "17   4/1/2024                4.9                    4.0   \n",
       "18   7/1/2024                4.9                    3.7   \n",
       "19  10/1/2024                4.8                    3.3   \n",
       "20   1/1/2025                4.7                    3.1   \n",
       "21   4/1/2025                4.6                    3.0   \n",
       "22   7/1/2025                4.6                    3.0   \n",
       "23  10/1/2025                4.6                    3.0   \n",
       "24   1/1/2026                4.6                    3.0   \n",
       "25   4/1/2026                4.6                    3.0   \n",
       "\n",
       "    5-year Treasury yield  10-year Treasury yield  House Price Index (Level)  \\\n",
       "0                     1.6                     1.8                      215.2   \n",
       "1                     1.2                     1.4                      217.8   \n",
       "2                     0.4                     0.7                      219.9   \n",
       "3                     0.3                     0.6                      226.9   \n",
       "4                     0.4                     0.9                      235.3   \n",
       "5                     0.6                     1.4                      243.0   \n",
       "6                     0.8                     1.6                      254.6   \n",
       "7                     0.8                     1.4                      266.3   \n",
       "8                     1.2                     1.6                      277.3   \n",
       "9                     1.9                     2.0                      290.3   \n",
       "10                    3.0                     3.0                      297.5   \n",
       "11                    3.3                     3.2                      297.6   \n",
       "12                    4.1                     3.9                      299.8   \n",
       "13                    4.0                     3.9                      301.3   \n",
       "14                    4.0                     3.8                      302.8   \n",
       "15                    3.9                     3.7                      304.3   \n",
       "16                    3.7                     3.6                      305.8   \n",
       "17                    3.6                     3.5                      307.4   \n",
       "18                    3.5                     3.4                      308.9   \n",
       "19                    3.4                     3.3                      310.4   \n",
       "20                    3.3                     3.3                      312.0   \n",
       "21                    3.2                     3.3                      313.5   \n",
       "22                    3.1                     3.3                      315.1   \n",
       "23                    3.0                     3.3                      316.6   \n",
       "24                    3.0                     3.2                      318.2   \n",
       "25                    2.9                     3.2                      319.8   \n",
       "\n",
       "    30Y10Y_MBSOAS_TY  \n",
       "0           10.12940  \n",
       "1           28.01090  \n",
       "2          -25.44510  \n",
       "3           13.27660  \n",
       "4           -1.74740  \n",
       "5          -33.27440  \n",
       "6          -15.01690  \n",
       "7          -20.65740  \n",
       "8           13.28500  \n",
       "9           34.03620  \n",
       "10           9.20502  \n",
       "11          55.20630  \n",
       "12          11.66230  \n",
       "13               NaN  \n",
       "14               NaN  \n",
       "15               NaN  \n",
       "16               NaN  \n",
       "17               NaN  \n",
       "18               NaN  \n",
       "19               NaN  \n",
       "20               NaN  \n",
       "21               NaN  \n",
       "22               NaN  \n",
       "23               NaN  \n",
       "24               NaN  \n",
       "25               NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scenario \n",
    "dt_base =pd.read_csv('Agency_MBS_Data_Base.csv')\n",
    "dt_stress =pd.read_csv('Agency_MBS_Data_Stress.csv')\n",
    "\n",
    "dt_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c9420a",
   "metadata": {},
   "source": [
    "##Set up Functions##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77682589",
   "metadata": {},
   "outputs": [],
   "source": [
    " # transform Raw Data \n",
    "    # indep = list of variable IDs \n",
    "    # indep_trans = the transformation used for each variable \n",
    "    # model_dat = data containing the history \n",
    "    # hist_start = start date of the history to use\n",
    "    # hist_end = last date of history to include in the transformation yyyy-mm\n",
    "    \n",
    "def fcst_data_prep(indep, indep_trans, model_dat, hist_start, hist_end):\n",
    "    \n",
    "    # independent variable transformation\n",
    "\n",
    "    base_drivers =model_dat['month']\n",
    "    base_drivers =pd.DataFrame(base_drivers)\n",
    "    \n",
    "    for k in range(len(indep)):\n",
    "        x = indep[k]\n",
    "        \n",
    "        exog_trans = model_dat[['month',x]] \n",
    "        \n",
    "        if len(base_drivers)>0:\n",
    "        \n",
    "            if 'QoQ' in indep_trans:          \n",
    "                exog_trans[x+'_QoQ'] =  exog_trans[x]/exog_trans[x].shift()-1            \n",
    "                \n",
    "            if 'YoY' in indep_trans:         \n",
    "                exog_trans[x+'_YoY'] = exog_trans[x]/exog_trans[x].shift(4)-1\n",
    "                               \n",
    "            if 'diff'in indep_trans:\n",
    "                exog_trans[x+'_diff'] = exog_trans[x]-exog_trans[x].shift()                \n",
    "               \n",
    "            if  'log' in indep_trans:\n",
    "                exog_trans[x+'_log'] = np.log(np.array(exog_trans[x], dtype = float))\n",
    "                \n",
    "            if  'log_diff' in indep_trans:\n",
    "                exog_trans[x+'_logDiff'] = np.log(np.array(exog_trans[x]/exog_trans[x].shift()), dtype = float)\n",
    "            \n",
    "            base_drivers = pd.merge(base_drivers, exog_trans, how ='left',on='month')\n",
    "    \n",
    "        else: print(x + \"is missing history\") \n",
    "           # base_drivers\n",
    "        \n",
    "        Date_Index = base_drivers[(base_drivers['month'] >= hist_start) & (base_drivers['month'] <= hist_end) ].index\n",
    "        base_drivers.drop(Date_Index, inplace=True)\n",
    "  \n",
    "    return base_drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "394dd3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Fitting Options & Diagnostics #\n",
    "# There are three options to model the data :  OLS with Constant,  OLS with HAC Errors,  & ARIMA \n",
    "\n",
    "def fit(hist_data, type, independent_var, dependent_var, order,backtest=None):\n",
    "    \n",
    "    #DataFrame for ADF & KPSS#\n",
    "    St = {'Variable_ID':[], 'ADF Statistic:':[], 'p-value:':[], 'Critical Values:':[],'Result':[] }\n",
    "    Stationary_ADF1 = pd.DataFrame(data=St) \n",
    "\n",
    "    St1 = {'Variable_ID':[], 'KPSS Statistic:':[], 'p-value:':[], 'Critical Values:':[],'Result':[] }\n",
    "    Stationary_KPSS1 = pd.DataFrame(data=St1)\n",
    "    \n",
    "    if type == 'OLS':\n",
    "        Y = hist_data[dependent_var]\n",
    "        X = hist_data[independent_var]\n",
    "        X = sm.add_constant(X) \n",
    "        #VIF testing\n",
    "        VIF = pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns )\n",
    "        #Stationarity Testing \n",
    "        Ind_var = independent_var\n",
    "        for r in range(len(Ind_var)):\n",
    "            print(r)\n",
    "            var = Ind_var[r]\n",
    "            x = hist_data[var] \n",
    "            print(var)\n",
    "            Stationary_ADF = test_stationary(var,x,'ADF', backtest) \n",
    "            Stationary_ADF1 = pd.concat([Stationary_ADF,Stationary_ADF1], ignore_index=True) \n",
    "            Stationary_KPSS = test_stationary(var,x,'KPSS', backtest) \n",
    "            Stationary_KPSS1 = pd.concat([Stationary_KPSS,Stationary_KPSS1], ignore_index=True) \n",
    "            \n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "        \n",
    "    elif type == 'OLS_HAC':\n",
    "        Y = hist_data[dependent_var]\n",
    "        X = hist_data[independent_var]\n",
    "        X = sm.add_constant(X)\n",
    "        #VIF testing\n",
    "        VIF = pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns ) \n",
    "        #Stationarity Testing \n",
    "        Ind_var = independent_var\n",
    "        for r in range(len(Ind_var)):\n",
    "            var = Ind_var[r]\n",
    "            x = hist_data[var] \n",
    "            Stationary_ADF = test_stationary(var,x,'ADF', backtest) \n",
    "            Stationary_ADF1 = pd.concat([Stationary_ADF,Stationary_ADF1], ignore_index=True) \n",
    "            Stationary_KPSS = test_stationary(var,x,'KPSS', backtest) \n",
    "            Stationary_KPSS1 = pd.concat([Stationary_KPSS,Stationary_KPSS1], ignore_index=True) \n",
    "            \n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit(cov_type='HAC', cov_kwds={'maxlags': 10})\n",
    "        \n",
    "    elif type == 'ARIMA':\n",
    "        endog = hist_data[dependent_var]\n",
    "        exog = hist_data[independent_var]\n",
    "        X = sm.add_constant(exog)\n",
    "        #VIF testing\n",
    "        VIF = pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns )\n",
    "        #Stationarity Testing \n",
    "        Ind_var = independent_var\n",
    "        for r in range(len(Ind_var)):\n",
    "            var = Ind_var[r]\n",
    "            x = hist_data[var] \n",
    "            Stationary_ADF = test_stationary(var,x,'ADF', backtest) \n",
    "            Stationary_ADF1 = pd.concat([Stationary_ADF,Stationary_ADF1], ignore_index=True) \n",
    "            Stationary_KPSS = test_stationary(var,x,'KPSS', backtest) \n",
    "            Stationary_KPSS1 = pd.concat([Stationary_KPSS,Stationary_KPSS1], ignore_index=True)\n",
    "            \n",
    "        model = sm.tsa.arima.ARIMA(endog, exog, order=order)\n",
    "        results = model.fit()\n",
    "   # else:\n",
    "      #  pass\n",
    "    return results, VIF, Stationary_ADF1, Stationary_KPSS1\n",
    "\n",
    "#Once a Model Summary is generated,  the additional insample diagnostic testing can be pulled out for analysis#\n",
    "# Output is defined below: \n",
    "# R2, MAE, RMSE : Model Goodness of Fit \n",
    "# Durbin Watsons: For Autocorrelation\n",
    "# Breuschpagan_P & GoldFeld_Quandt: For Heteroscatisticy \n",
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / actual)) * 100\n",
    "\n",
    "def model_diagnostic(results, type):\n",
    "    model_diagnostic = pd.DataFrame(columns = ['r2', 'mae', 'rmse', 'dw', 'Goldfeld_Quandt_p', 'breuschpagan_p'])\n",
    "    if type in ['OLS', 'OLS_HAC']:\n",
    "        metrics_map = {\n",
    "            'r2': results.rsquared,\n",
    "            'mae': sum(abs(results.resid))/len(results.resid),\n",
    "            'rmse': np.sqrt(results.mse_resid),\n",
    "            'dw': durbin_watson(results.resid),\n",
    "            'Goldfeld_Quandt_p': sms.het_goldfeldquandt(results.resid, results.model.exog)[1],\n",
    "            'breuschpagan_p': sms.het_breuschpagan(results.resid, results.model.exog)[1]\n",
    "        }\n",
    "    elif type in ['ARIMA']:\n",
    "        metrics_map = {\n",
    "            'r2': 1 - results.sse / sum((results.data.endog - np.mean(results.data.endog)) ** 2),\n",
    "            'mae': results.mae,\n",
    "            'rmse': np.sqrt(results.mse),\n",
    "            'dw': durbin_watson(results.resid),\n",
    "            'Goldfeld_Quandt_p': sms.het_goldfeldquandt(results.resid, results.model.exog)[1],\n",
    "            'breuschpagan_p': sms.het_breuschpagan(results.resid, results.model.exog)[1]\n",
    "        }\n",
    "    else:\n",
    "        pass\n",
    "    return model_diagnostic.append(metrics_map, ignore_index=True)\n",
    "\n",
    "\n",
    "def model_analysis(results, type):\n",
    "    if type in ['OLS','OLS_HAC']:\n",
    "        analysis_df = results.summary()\n",
    "    elif type in ['ARIMA']:\n",
    "        analysis_df = results.summary()\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "    return analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dd02598",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Stationary Tests of Data\n",
    "    # var_id - the variable ID being used in the testing \n",
    "    # test_series - the data series to use to test. It only accept a single data series without any NA values \n",
    "    # test_type - Defining what kind of test to use for stationarity testing. \n",
    "    \n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "\n",
    "def kpss_test(var_id,series, **kw):    \n",
    "    statistic, p_value, n_lags, critical_values = kpss(series, **kw)\n",
    "    # Format Output\n",
    "    for key, value in critical_values.items():\n",
    "        #print(f'   {key} : {value}')\n",
    "        print(f'{var_id} KPSS Result: The series is {\"not \" if p_value <.05 else \"\"}stationary')\n",
    "        if p_value <.05: result='not stationary' \n",
    "        else: result='stationary' \n",
    "    \n",
    "    St1 = {'Variable_ID':[var_id], 'KPSS Statistic:':[statistic], 'p-value:':[p_value], 'Critical Values:':[critical_values],'Result':[result] }\n",
    "    test_summary = pd.DataFrame(data=St1)\n",
    "    \n",
    "    return test_summary\n",
    "\n",
    "def test_stationary(var_id, test_series, test_type, backtest):\n",
    "\n",
    "    if backtest==None:    \n",
    "    # ADF test\n",
    "        if test_type == 'ADF':\n",
    "            ADF_result = adfuller(test_series, autolag='AIC')\n",
    "            for key, value in ADF_result[4].items():   \n",
    "                print(f'{var_id} ADF Result: The series is {\"not \" if ADF_result[1] > 0.05 else \"\"}stationary')\n",
    "                if ADF_result[1] > 0.05: result_1='not stationary' \n",
    "                else: result_1='stationary' \n",
    "    \n",
    "            St = {'Variable_ID':[var_id], 'ADF Statistic:':[ADF_result[0]], 'p-value:':[ADF_result[1]], 'Critical Values:':[ADF_result[4]],'Result':[result_1] }\n",
    "            test_summary = pd.DataFrame(data=St)\n",
    "    \n",
    "    # KPSS test\n",
    "    \n",
    "        if test_type == 'KPSS':  \n",
    "            test_summary = kpss_test(var_id,test_series) \n",
    "    else:\n",
    "        test_summary= pd.DataFrame(data=[\"backtesting\"])\n",
    "    \n",
    "    return test_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b3e1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Plotting Features#\n",
    "\n",
    "#Plot the Autocorrelation and Residiuals \n",
    "#results: The Fitted Model results \n",
    "#dependent_var: The dependent variable in the Fitted Model \n",
    "\n",
    "def residual_plot(results, dependent_var, pdf):\n",
    "    # residual acf, pacf, qq-plot\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 4), dpi=80)\n",
    "    plot_acf(results.resid, ax=ax1, lags=9)\n",
    "    plot_pacf(results.resid, ax=ax2, lags=9)\n",
    "    sm.qqplot(results.resid, stats.norm, fit=True, line=\"45\", ax=ax3)\n",
    "    ax3.set_title('Q-Q plot')\n",
    "    fig.suptitle(dependent_var)\n",
    "    plt.savefig(f\"Residual_{pdf}\")\n",
    "    plt.close(fig)\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "def forecast(results, hist_data, type):\n",
    "    if type in ['OLS', 'OLS_HAC']:\n",
    "        hist_data = sm.add_constant(hist_data)\n",
    "        ypred = results.predict(hist_data)\n",
    "    elif type in [\"ARIMA\"]:\n",
    "        ypred1 = results.predict(exog=hist_data[:-9]).to_list()\n",
    "        ypred2 = results.forecast(exog=hist_data.tail(9), steps=9).to_list()\n",
    "        ypred =ypred1+ypred2\n",
    "        #ypred =ypred[0].squeeze(axis = 0)\n",
    "        print(ypred)\n",
    "    else:\n",
    "        pass\n",
    "    return ypred\n",
    "\n",
    "def forecast_scenario(results, hist_data, type):\n",
    "    if type in ['OLS', 'OLS_HAC']:\n",
    "        hist_data = sm.add_constant(hist_data)\n",
    "        ypred = results.predict(hist_data)\n",
    "    elif type in [\"ARIMA\"]:\n",
    "        ypred = results.forecast(exog=hist_data, steps=17).to_list()\n",
    "    else:\n",
    "        pass\n",
    "    return ypred\n",
    "\n",
    "######################Backtesting plot with Out of Time /Out of Sample############################################ \n",
    "\n",
    "#hist_data : Full data with the neccessary transformation \n",
    "#type: the type of model being used - OLS, OLS_HAC, ARMIA\n",
    "#independent_var:  the list of transformed independent variables needed for the model \n",
    "#dependent_var: The transformed dependent variable.  \n",
    "#dependent_var_level: the level depdendent variable. \n",
    "#testingQ: this number of quarters to be removed for testing Out of Sample \n",
    "#tran_type: The transformation type of the dependent variable - diff, YoY \n",
    "#order: if the model type is ARMIA, set the residual order (1,0,0)\n",
    "#VM:  If the model is forecasting Velocity of Money, the VM = True to do the additional transformation needed \n",
    "#NGDP: if the VM=True, the NGDP field needs to be set with the NGDP to be used in the transformation \n",
    "#Money_Supply:  If the VM = True, the Money_Supply also needs to be set with the money supply.  \n",
    "#This is used for plotting actuals vs predicted\n",
    "\n",
    "def backtesting_plot(hist_data, type, independent_var, dependent_var_level, dependent_var, pdf, testingQ, tran_type, order , \n",
    "                     Special_transformation=False , NGDP=False ,Money_Supply =False):\n",
    "\n",
    "    # 9 quarter backtesting\n",
    "    hist_data = hist_data.dropna()\n",
    "    insample_hist = hist_data[:-testingQ]\n",
    "    \n",
    "    #call the fit function to come up with the insample estimates#\n",
    "    results, VIF, Stationary_ADF1 , Stationary_KPSS1 = fit(insample_hist, type, independent_var, dependent_var, order, backtest=True)\n",
    "    \n",
    "    insample_analysis_df = model_analysis(results, type)\n",
    "    insample_diagnostic_df = model_diagnostic(results, type)\n",
    "        \n",
    "    hist_data[\"month\"] = pd.to_datetime(hist_data['month'].astype('str'))   \n",
    "    forecast_hist = forecast(results, hist_data[independent_var], type)\n",
    "\n",
    "    cutoff_date = hist_data['month'].iloc[-testingQ]\n",
    "    cutoff_date2 = hist_data['month'].iloc[-(testingQ+2)]\n",
    "    hist_data['prediction']=forecast_hist\n",
    "    forecast_hist =pd.DataFrame(forecast_hist)\n",
    "    hist_data2 =hist_data\n",
    "    \n",
    "    hist_data_OutofSample = hist_data[hist_data['month'] > cutoff_date2]   \n",
    "    backtest_untransformed_prediction = hist_data[['month','prediction', dependent_var]]\n",
    "    \n",
    "    # transformback For Any Special Variable. THis needs to be updated to allow for any unique transformation.  It is now setup \n",
    "    # for Money SUpply.  But it can be updated to reflect any other variable transformation by adjusting the below code below#\n",
    "    \n",
    "    if Special_transformation == True: \n",
    "        \n",
    "        hist_data_OutofSample['level_prediction_full'] = untransformation(hist_data_OutofSample['prediction'],hist_data_OutofSample,dependent_var_level,tran_type)\n",
    "        hist_data2['level_prediction'] = untransformation_onestep(forecast_hist,hist_data2,dependent_var_level,tran_type)\n",
    "              \n",
    "        hist_data_OutofSample['prediction_MS'] = hist_data_OutofSample[NGDP]/hist_data_OutofSample['level_prediction_full'] \n",
    "        hist_data2['prediction_MS'] = hist_data2[NGDP]/hist_data2['level_prediction'] \n",
    "        \n",
    "        MS_RMSE = sqrt(mean_squared_error(hist_data_OutofSample[Money_Supply], hist_data_OutofSample['prediction_MS']))\n",
    "        Y_Actual_Average = mean(hist_data_OutofSample[Money_Supply]) \n",
    "        MS_RMSE_N = (MS_RMSE/Y_Actual_Average) * 100\n",
    "       \n",
    "        \n",
    "        MS_MAPE = mape(hist_data_OutofSample[Money_Supply], hist_data_OutofSample['prediction_MS'])\n",
    "        \n",
    "        backtest_transformed_prediction = hist_data_OutofSample[['month','level_prediction_full','prediction_MS',NGDP,Money_Supply]]\n",
    "        backtest_transformed_prediction['MS_RMSE']=MS_RMSE\n",
    "        backtest_transformed_prediction['MS_MAPE']=MS_MAPE\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.plot('month', Money_Supply, data=hist_data, label='Actual', color='black')\n",
    "        ax.plot('month', 'prediction_MS', data=hist_data[:-testingQ], label='In-sample Fitted', color='red')\n",
    "        ax.plot('month', 'prediction_MS', data=hist_data_OutofSample, label='Out-sample Fitted', color='blue', linestyle='dashed')\n",
    "        plt.axvline(x=pd.to_datetime(cutoff_date), color='lightgray')\n",
    "        ax.set_title('Fitted vs Actual')\n",
    "        ax.set_ylabel(Money_Supply)\n",
    "        ax.set_xlabel('month')\n",
    "        ax.legend()\n",
    "        plt.savefig(f\"MS_Backtesting_{pdf}\")\n",
    "        plt.close(fig)\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "    \n",
    "    # No Special Transformation.  THis is a plain vanilla regression backtesting # \n",
    "    \n",
    "    else:       \n",
    "        \n",
    "        hist_data_OutofSample['level_prediction_full'] = untransformation(hist_data_OutofSample['prediction'],hist_data_OutofSample,dependent_var_level,tran_type)\n",
    "        hist_data2['level_prediction'] = untransformation_onestep(forecast_hist,hist_data2,dependent_var_level,tran_type)\n",
    "              \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.plot('month', dependent_var, data=hist_data, label='Actual_Untransformed', color='black')\n",
    "        ax.plot('month', 'prediction', data=hist_data[:-testingQ], label='In-sample Fitted Untransformed', color='red')\n",
    "        ax.plot('month', 'prediction', data=hist_data_OutofSample, label='Out-sample Fitted Untransformed', color='blue', linestyle='dashed')\n",
    "        plt.axvline(x=pd.to_datetime(cutoff_date), color='lightgray')\n",
    "        ax.set_title('Predicted Fitted vs Actual')\n",
    "        ax.set_ylabel(dependent_var)\n",
    "        ax.set_xlabel('month')\n",
    "        ax.legend()\n",
    "        plt.savefig(f\"Unstransformed_Backtesting_{pdf}\")\n",
    "        plt.close(fig)\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        \n",
    "        Actuals = hist_data_OutofSample[dependent_var_level]\n",
    "        Predicted = hist_data_OutofSample['level_prediction_full']\n",
    "                \n",
    "        MS_MAPE = mape(Actuals[-9:],Predicted[-9:])       \n",
    "        MS_RMSE = sqrt(mean_squared_error(Actuals[-9:],Predicted[-9:])) \n",
    "        Y_Actual_Average = mean(Actuals[-9:])         \n",
    "        MS_RMSE_N = (MS_RMSE/Y_Actual_Average) * 100\n",
    "        \n",
    "        backtest_transformed_prediction = hist_data_OutofSample[['month',dependent_var_level,'level_prediction_full']]\n",
    "        backtest_transformed_prediction['MS_RMSE_N']=MS_RMSE_N\n",
    "        backtest_transformed_prediction['MS_MAPE']=MS_MAPE\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.plot('month', dependent_var_level, data=hist_data, label='Actual_Transformed', color='black')\n",
    "        ax.plot('month', 'level_prediction', data=hist_data2[:-testingQ], label='In-sample Fitted Transformed', color='red')\n",
    "        ax.plot('month', 'level_prediction_full', data=hist_data_OutofSample, label='Out-sample Fitted Transformed', color='blue', linestyle='dashed')\n",
    "        plt.axvline(x=pd.to_datetime(cutoff_date), color='lightgray')\n",
    "        ax.set_title('Level Fitted vs Actual')\n",
    "        ax.set_ylabel(dependent_var_level)\n",
    "        ax.set_xlabel('month')\n",
    "        ax.legend()\n",
    "        plt.savefig(f\"Transformed_Backtesting_{pdf}\")\n",
    "        plt.close(fig)\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        \n",
    "    return insample_analysis_df, insample_diagnostic_df, backtest_untransformed_prediction, backtest_transformed_prediction\n",
    "\n",
    "\n",
    "#################################Transfromation of Dependent Variables ##################################################\n",
    "\n",
    "#Untransformation_Based on the prior PRedicted Level \n",
    "\n",
    "#sce_forecast - the data of the predicted values. this is the value that is the transformed form  \n",
    "#model_dat :  the data set of the original form.  The function will pull the latest actual T0 and transforms the predicted back to the level \n",
    "#depvar: The variable name of the level form in the model_dat dataframe. \n",
    "#type:  The form of the transformation to convert the predicted back to the level \n",
    "\n",
    "def untransformation(sce_forecast,model_dat, depvar, type):\n",
    "    \n",
    "    if type == 'YoY':\n",
    "        sce_forecast_trans = []\n",
    "        for i in range(len(sce_forecast)):\n",
    "            if i == 0:\n",
    "                tn = model_dat[depvar].iloc[0]\n",
    "            if i == 1:\n",
    "                tn = model_dat[depvar].iloc[1]\n",
    "            if i == 2:\n",
    "                tn = model_dat[depvar].iloc[2]\n",
    "            if i == 3:\n",
    "                tn = model_dat[depvar].iloc[3]\n",
    "            if i > 3:\n",
    "                tn = sce_forecast_trans[i-4]*(sce_forecast.iloc[i]+1)\n",
    "            sce_forecast_trans = np.append(sce_forecast_trans, tn)\n",
    "    \n",
    "    # transform QoQ forecast back to level\n",
    "    if type == 'QoQ':\n",
    "        sce_forecast_trans = []\n",
    "        for i in range(len(sce_forecast)):\n",
    "            if i == 0:\n",
    "                tn = model_dat[depvar].iloc[0]\n",
    "               \n",
    "            if i > 0:\n",
    "                tn = model_dat[depvar].iloc[i-1]*(sce_forecast.iloc[i]+1)\n",
    "                \n",
    "            sce_forecast_trans = np.append(sce_forecast_trans, tn)\n",
    "    \n",
    "    # transform diff forecast back to level\n",
    "    if type == 'diff':\n",
    "        sce_forecast_trans = []\n",
    "        for i in range(len(sce_forecast)):\n",
    "            if i == 0:\n",
    "                tn = model_dat[depvar].iloc[0]\n",
    "            if i > 0:\n",
    "                tn = sce_forecast_trans[i-1] + sce_forecast.iloc[i]\n",
    "            sce_forecast_trans = np.append(sce_forecast_trans, tn)\n",
    "            \n",
    "    # transform diff forecast back to level\n",
    "    if type == 'logDiff':\n",
    "        sce_forecast_trans = []\n",
    "        for i in range(len(sce_forecast)):\n",
    "            if i == 0:\n",
    "                tn = model_dat[depvar].iloc[0]\n",
    "            if i > 0:\n",
    "                tn = np.exp(np.log(sce_forecast_trans[i-1]) + sce_forecast.iloc[i])\n",
    "            sce_forecast_trans = np.append(sce_forecast_trans, tn)            \n",
    "            \n",
    "    # level\n",
    "    if type == 'level':\n",
    "        sce_forecast_trans = np.array(sce_forecast)\n",
    "     \n",
    "    # log transformation back to level\n",
    "    if type == 'log':\n",
    "        sce_forecast_trans = np.exp(sce_forecast)\n",
    "        \n",
    "    return sce_forecast_trans\n",
    "\n",
    "####Untransformation_Based on one-step ahead forecast###### \n",
    "\n",
    "def untransformation_onestep(sce_forecast,model_dat, depvar, type):\n",
    "\n",
    "    \n",
    "    if type == 'YoY':\n",
    "        sce_forecast_trans_one_step = []\n",
    "        for i in range(len(sce_forecast)):\n",
    "            if i == 0:\n",
    "                tx = model_dat[depvar].iloc[0]\n",
    "                tn=tx\n",
    "            if i == 1:\n",
    "                tx = model_dat[depvar].iloc[1]\n",
    "                tn=tx\n",
    "            if i == 2:\n",
    "                tn = model_dat[depvar].iloc[2]\n",
    "                tn=tx\n",
    "            if i == 3:\n",
    "                tx = model_dat[depvar].iloc[3]\n",
    "                tn=tx\n",
    "            if i > 3:\n",
    "                tx = model_dat[depvar].iloc[i-4]\n",
    "                tn = tx*(sce_forecast.iloc[i]+1)\n",
    "            \n",
    "            sce_forecast_trans_one_step = np.append(sce_forecast_trans_one_step, tn)\n",
    "    \n",
    "    # transform QoQ forecast back to level\n",
    "    if type == 'QoQ':\n",
    "        sce_forecast_trans_one_step = []\n",
    "        for i in range(len(sce_forecast)):\n",
    "            if i == 0:\n",
    "                tn = model_dat[depvar].iloc[0] \n",
    "            if i > 0:\n",
    "                tn = model_dat[depvar].iloc[i-1]*(sce_forecast.iloc[i]+1)\n",
    "                    \n",
    "            sce_forecast_trans_one_step = np.append(sce_forecast_trans_one_step, tn)\n",
    "           \n",
    "    \n",
    "    # transform diff forecast back to level\n",
    "    if type == 'diff':\n",
    "        sce_forecast_trans_one_step = []\n",
    "        for i in range(len(sce_forecast)):\n",
    "            if i == 0:\n",
    "                tn = model_dat[depvar].iloc[0]          \n",
    "            if i > 0:               \n",
    "                tn = model_dat[depvar].iloc[i-1]+sce_forecast.iloc[i]\n",
    "                \n",
    "            sce_forecast_trans_one_step = np.append(sce_forecast_trans_one_step, tn)\n",
    "            \n",
    "    # transform diff forecast back to level\n",
    "    if type == 'logDiff':\n",
    "        sce_forecast_trans_one_step = []\n",
    "        for i in range(len(sce_forecast)):\n",
    "            if i == 0:\n",
    "                tn = model_dat[depvar].iloc[0]\n",
    "            if i > 0:\n",
    "                tn = np.exp(np.log(model_dat[depvar].iloc[i-1])+sce_forecast.iloc[i])\n",
    "            \n",
    "            sce_forecast_trans_one_step = np.append(sce_forecast_trans_one_step, tn)            \n",
    "            \n",
    "    # level\n",
    "    if type == 'level':\n",
    "        sce_forecast_trans_one_step = np.array(sce_forecast)\n",
    "     \n",
    "    # log transformation back to level\n",
    "    if type == 'log':\n",
    "        sce_forecast_trans_one_step = np.exp(sce_forecast)\n",
    "        \n",
    "    return sce_forecast_trans_one_step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b4413ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXCEL OUTPUT FUNCTION -  The workbook name is set in the function \n",
    "\n",
    "#out:  Full Model Fit Summary -model_Fit.summary() \n",
    "#Model_DA: Model Diagnostics -model_diagnostic(Model_Fit,'OLS')\n",
    "#VIF:  Vif output from the fit() from the full model \n",
    "#Insample_parm : The backtesting parmeters from the backtesting() function \n",
    "#Country_Code: The country code used for the tab and images naming \n",
    "\n",
    "def excel_output(out,Model_DA,VIF,Insample_parm,Stationary_ADF1,Stationary_KPSS1,Full_Estimation_Data,\n",
    "                 bt_Estimation_Data,Country_Code,bt_Forecast,bt_prediction,scenario_base_data, \n",
    "                 scenario_stress_data):\n",
    " #Full Sample Estimates# \n",
    "    table1 = pd.DataFrame(out.tables[0])\n",
    "    table2 = pd.DataFrame(out.tables[1])\n",
    "    table3 = pd.DataFrame(out.tables[2])\n",
    "    table4 = pd.DataFrame(VIF)\n",
    "    table4.columns = ['VIF']\n",
    "    \n",
    "    Full_Sample = table1.append(table2).append(table3)\n",
    "    \n",
    "    Data_Summary = Full_Estimation_Data.describe()\n",
    "    Data_Summary_StartDate= Full_Estimation_Data.head(1)\n",
    "    Data_Summary_EndDate= Full_Estimation_Data.tail(1)\n",
    "    \n",
    "    Data_Summary2 = bt_Estimation_Data.describe()\n",
    "    Data_Summary2_StartDate= bt_Estimation_Data.head(1)\n",
    "    Data_Summary2_EndDate= bt_Estimation_Data.tail(1)\n",
    "    \n",
    "#Backtesting Estimates# \n",
    "    table5 = pd.DataFrame(Insample_parm.tables[0])\n",
    "    table6 = pd.DataFrame(Insample_parm.tables[1])\n",
    "    table7 = pd.DataFrame(Insample_parm.tables[2])\n",
    "\n",
    "#Output all Results to Excel Worksheet#\n",
    "    writer = pd.ExcelWriter(f'{Country_Code}_Debt_Model.xlsx', engine='xlsxwriter')\n",
    "    text1 = pd.DataFrame({'Full Sample Parameters':['Full Sample Parameters']})\n",
    "    text1.to_excel(writer, sheet_name=f'{Country_Code}', startrow=1)\n",
    "    Full_Sample.to_excel(writer, sheet_name=f'{Country_Code}', startrow=2)\n",
    "    Model_DA.to_excel(writer, sheet_name=f'{Country_Code}', startrow=21)\n",
    "    table4.to_excel(writer, sheet_name=f'{Country_Code}', startrow=24,startcol =2)\n",
    "    Stationary_ADF1.to_excel(writer, sheet_name=f'{Country_Code}', startrow=30,startcol =2)\n",
    "    Stationary_KPSS1.to_excel(writer, sheet_name=f'{Country_Code}', startrow=30,startcol =10)\n",
    "    Data_Summary.to_excel(writer, sheet_name=f'{Country_Code}', startrow=1,startcol =20)\n",
    "    Data_Summary_StartDate.to_excel(writer, sheet_name=f'{Country_Code}', startrow=11,startcol =20)\n",
    "    Data_Summary_EndDate.to_excel(writer, sheet_name=f'{Country_Code}', startrow=13,startcol =20)\n",
    "    \n",
    "    Data_Summary2.to_excel(writer, sheet_name=f'{Country_Code}', startrow=1,startcol =28)\n",
    "    Data_Summary2_StartDate.to_excel(writer, sheet_name=f'{Country_Code}', startrow=11,startcol =28)\n",
    "    Data_Summary2_EndDate.to_excel(writer, sheet_name=f'{Country_Code}', startrow=13,startcol =28)\n",
    "    \n",
    "    text2 = pd.DataFrame({'Backtesting Sample Parameters':['Backtesting Sample Parameters']})\n",
    "    text2.to_excel(writer, sheet_name=f'{Country_Code}', startrow=1, startcol =11)\n",
    "    table5.to_excel(writer, sheet_name=f'{Country_Code}', startrow=2,startcol =11)\n",
    "    table6.to_excel(writer, sheet_name=f'{Country_Code}', startrow=12,startcol =11)\n",
    "    table7.to_excel(writer, sheet_name=f'{Country_Code}', startrow=18,startcol =11)\n",
    "    Insample_perform.to_excel(writer, sheet_name=f'{Country_Code}', startrow=21,startcol =11 )\n",
    "    \n",
    "    bt_Forecast.to_excel(writer, sheet_name=f'{Country_Code}_BT_Data', startrow=1, startcol =1)\n",
    "    bt_prediction.to_excel(writer, sheet_name=f'{Country_Code}_BT_Data', startrow=1, startcol =8)\n",
    "\n",
    "    scenario_base_data.to_excel(writer, sheet_name=f'{Country_Code}_Base_frc', startrow=1, startcol =1)\n",
    "    scenario_stress_data.to_excel(writer, sheet_name=f'{Country_Code}_Stress_frc', startrow=1, startcol =1)\n",
    "    \n",
    "    \n",
    "    worksheet = writer.sheets[f'{Country_Code}']\n",
    "    worksheet.insert_image('A38',f\"Unstransformed_Backtesting_{pdf}\")\n",
    "    worksheet.insert_image('Q35',f\"Backtesting_{pdf}\")\n",
    "    worksheet.insert_image('A64',f\"Transformed_Backtesting_{pdf}\")\n",
    "    worksheet.insert_image('A90',f\"Residual_{pdf}\")\n",
    "    worksheet.insert_image('Q59',f\"ScenarioForecast_{pdf}\")\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fde57cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Generate Scenario Forecasts by taking the scenario output defined in the first couple of code\n",
    "#results:  The fitted model output.  This should be the full development model fit\n",
    "#scenario_base_data :  The base forecast that has the transformation as required by the model. The data needs the independent variable and the untransformed\n",
    "#scenario_stress_data: The stress forecast that has the transformation as required by the model. The data needs the independent variable and the untransformed\n",
    "#independent_var: The list of independent variables in the model.  This is the list of the transformation independent variable. \n",
    "#dependent_var: The dependent variable - Untransformed dependent\n",
    "#pdf: The name of the graph of the scenario plots\n",
    "#type: the model fit type: OLS, OLS_HAC, ARIMA\n",
    "#tran_type:  The transformation type of the dependent variable. If the variable doesn't need transformation set it ='Level' \n",
    "\n",
    "def scenario_output(results, scenario_base_data, scenario_stress_data ,independent_var, dependent_var,pdf, type,  tran_type):\n",
    "    \n",
    "    #Generate the predicted scenario output.  This is the output of the transformation \n",
    "    base_forecast = forecast_scenario(results, scenario_base_data[independent_var], type)\n",
    "    base_forecast=pd.DataFrame(base_forecast)\n",
    "    \n",
    "    scenario_base_data['ypred']=base_forecast \n",
    "    base_forecast=pd.DataFrame(base_forecast)\n",
    "    \n",
    "    stress_forecast = forecast_scenario(results, scenario_stress_data[independent_var], type)\n",
    "    stress_forecast=pd.DataFrame(stress_forecast)\n",
    "    \n",
    "    scenario_base_data[\"month\"] = pd.to_datetime(scenario_base_data['month'].astype('str'))  \n",
    "    scenario_stress_data[\"month\"] = pd.to_datetime(scenario_stress_data['month'].astype('str'))  \n",
    "    \n",
    "    scenario_base_data['prediction'] = untransformation(base_forecast,scenario_base_data,dependent_var,tran_type)\n",
    "    scenario_stress_data['prediction'] = untransformation(stress_forecast,scenario_stress_data,dependent_var,tran_type)\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    #ax.plot('month', 'ypred', data=scenario_base_data, label='Predicted_Base', color='black', linestyle='dashed')\n",
    "   #ax.plot('month', 'ypred', data=scenario_stress_data, label='Predicted_Stress', color='yellow', linestyle='dashed')\n",
    "    ax.plot('month', 'prediction', data=scenario_base_data, label='Predicted_Base_Level', color='blue', linestyle='dashed')\n",
    "    ax.plot('month', 'prediction', data=scenario_stress_data, label='Predicted_Stress_Level', color='red', linestyle='dashed')\n",
    "    ax.set_title('Scenario Forecasts')\n",
    "    ax.set_ylabel(dependent_var)\n",
    "    ax.set_xlabel('month')\n",
    "    ax.legend()\n",
    "    plt.savefig(f\"ScenarioForecast_{pdf}\")\n",
    "    plt.close(fig)\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "           \n",
    "    return scenario_base_data , scenario_stress_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be83f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stepwise Selection \n",
    "def backward_regression(X, y):\n",
    "    cols=list(X.columns)\n",
    "    cols.remove(y)\n",
    "    \n",
    "    #Backward Elimination\n",
    "    pmax = 1\n",
    "    while (len(cols)>0):\n",
    "        p= []\n",
    "        X_1= X[cols]\n",
    "        y_value = X[y]\n",
    "        \n",
    "        X_1 = sm.add_constant(X_1)\n",
    "\n",
    "        model = sm.OLS(y_value,X_1).fit()\n",
    "\n",
    "        p = pd.Series(model.pvalues.values[1:],index = cols)\n",
    "        pmax = max(p)\n",
    "        feature_with_p_max = p.idxmax()\n",
    "        \n",
    "        if(pmax>0.05):\n",
    "            cols.remove(feature_with_p_max)\n",
    "            print(f'{feature_with_p_max} is insignificant and dropped from the backward selection: p-value {pmax}')\n",
    "        else:\n",
    "            break\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dd98dc",
   "metadata": {},
   "source": [
    "#Set up intitial Candidate Variables#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d78b9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        month  30Y10Y_MBSOAS_TY  30Y10Y_MBSOAS_TY_QoQ  30Y10Y_MBSOAS_TY_diff  \\\n",
      "0    7/1/2009           0.00000                   NaN                    NaN   \n",
      "1   10/1/2009           0.00000                   NaN                0.00000   \n",
      "2    1/1/2010           0.00000                   NaN                0.00000   \n",
      "3    4/1/2010           0.00000                   NaN                0.00000   \n",
      "4    7/1/2010           0.00000                   NaN                0.00000   \n",
      "5   10/1/2010           0.00000                   NaN                0.00000   \n",
      "6    1/1/2011          18.08130                   inf               18.08130   \n",
      "7    4/1/2011          21.47880              0.187901                3.39750   \n",
      "8    7/1/2011          32.61530              0.518488               11.13650   \n",
      "9   10/1/2011          37.57190              0.151972                4.95660   \n",
      "10   1/1/2012          28.55870             -0.239892               -9.01320   \n",
      "11   4/1/2012          27.87350             -0.023993               -0.68520   \n",
      "12   7/1/2012          15.63040             -0.439238              -12.24310   \n",
      "13  10/1/2012         -13.95950             -1.893099              -29.58990   \n",
      "14   1/1/2013           7.09720             -1.508414               21.05670   \n",
      "15   4/1/2013          12.80500              0.804233                5.70780   \n",
      "16   7/1/2013          35.28420              1.755502               22.47920   \n",
      "17  10/1/2013          20.14430             -0.429084              -15.13990   \n",
      "18   1/1/2014          13.67310             -0.321242               -6.47120   \n",
      "19   4/1/2014          17.69770              0.294344                4.02460   \n",
      "20   7/1/2014          17.05320             -0.036417               -0.64450   \n",
      "21  10/1/2014          12.33960             -0.276406               -4.71360   \n",
      "22   1/1/2015           8.81610             -0.285544               -3.52350   \n",
      "23   4/1/2015           9.42510              0.069078                0.60900   \n",
      "24   7/1/2015          10.67690              0.132816                1.25180   \n",
      "25  10/1/2015           9.04580             -0.152769               -1.63110   \n",
      "26   1/1/2016          17.45220              0.929315                8.40640   \n",
      "27   4/1/2016          22.89060              0.311617                5.43840   \n",
      "28   7/1/2016          17.12570             -0.251846               -5.76490   \n",
      "29  10/1/2016           5.41746             -0.683665              -11.70824   \n",
      "30   1/1/2017           9.54164              0.761276                4.12418   \n",
      "31   4/1/2017          14.21230              0.489503                4.67066   \n",
      "32   7/1/2017          13.68020             -0.037439               -0.53210   \n",
      "33  10/1/2017           7.01862             -0.486950               -6.66158   \n",
      "34   1/1/2018          13.01150              0.853854                5.99288   \n",
      "35   4/1/2018          22.83000              0.754602                9.81850   \n",
      "36   7/1/2018          20.88740             -0.085090               -1.94260   \n",
      "37  10/1/2018          31.26280              0.496730               10.37540   \n",
      "38   1/1/2019          22.17800             -0.290595               -9.08480   \n",
      "39   4/1/2019          32.02820              0.444143                9.85020   \n",
      "40   7/1/2019          22.48420             -0.297987               -9.54400   \n",
      "41  10/1/2019          41.86950              0.862174               19.38530   \n",
      "42   1/1/2020          10.12940             -0.758072              -31.74010   \n",
      "43   4/1/2020          28.01090              1.765307               17.88150   \n",
      "44   7/1/2020         -25.44510             -1.908400              -53.45600   \n",
      "45  10/1/2020          13.27660             -1.521774               38.72170   \n",
      "46   1/1/2021          -1.74740             -1.131615              -15.02400   \n",
      "47   4/1/2021         -33.27440             18.042234              -31.52700   \n",
      "48   7/1/2021         -15.01690             -0.548695               18.25750   \n",
      "49  10/1/2021         -20.65740              0.375610               -5.64050   \n",
      "50   1/1/2022          13.28500             -1.643111               33.94240   \n",
      "51   4/1/2022          34.03620              1.562002               20.75120   \n",
      "52   7/1/2022           9.20502             -0.729552              -24.83118   \n",
      "53  10/1/2022          55.20630              4.997412               46.00128   \n",
      "54   1/1/2023          11.66230             -0.788751              -43.54400   \n",
      "\n",
      "    Unemployment rate  Unemployment rate_QoQ  Unemployment rate_diff  \\\n",
      "0                 9.3                    NaN                     NaN   \n",
      "1                 9.6               0.032258                     0.3   \n",
      "2                 9.9               0.031250                     0.3   \n",
      "3                 9.8              -0.010101                    -0.1   \n",
      "4                 9.6              -0.020408                    -0.2   \n",
      "5                 9.5              -0.010417                    -0.1   \n",
      "6                 9.5               0.000000                     0.0   \n",
      "7                 9.0              -0.052632                    -0.5   \n",
      "8                 9.1               0.011111                     0.1   \n",
      "9                 9.0              -0.010989                    -0.1   \n",
      "10                8.6              -0.044444                    -0.4   \n",
      "11                8.3              -0.034884                    -0.3   \n",
      "12                8.2              -0.012048                    -0.1   \n",
      "13                8.0              -0.024390                    -0.2   \n",
      "14                7.8              -0.025000                    -0.2   \n",
      "15                7.7              -0.012821                    -0.1   \n",
      "16                7.5              -0.025974                    -0.2   \n",
      "17                7.2              -0.040000                    -0.3   \n",
      "18                6.9              -0.041667                    -0.3   \n",
      "19                6.7              -0.028986                    -0.2   \n",
      "20                6.2              -0.074627                    -0.5   \n",
      "21                6.1              -0.016129                    -0.1   \n",
      "22                5.7              -0.065574                    -0.4   \n",
      "23                5.5              -0.035088                    -0.2   \n",
      "24                5.4              -0.018182                    -0.1   \n",
      "25                5.1              -0.055556                    -0.3   \n",
      "26                5.0              -0.019608                    -0.1   \n",
      "27                4.9              -0.020000                    -0.1   \n",
      "28                4.9               0.000000                     0.0   \n",
      "29                4.9               0.000000                     0.0   \n",
      "30                4.8              -0.020408                    -0.1   \n",
      "31                4.6              -0.041667                    -0.2   \n",
      "32                4.4              -0.043478                    -0.2   \n",
      "33                4.3              -0.022727                    -0.1   \n",
      "34                4.2              -0.023256                    -0.1   \n",
      "35                4.0              -0.047619                    -0.2   \n",
      "36                3.9              -0.025000                    -0.1   \n",
      "37                3.8              -0.025641                    -0.1   \n",
      "38                3.8               0.000000                     0.0   \n",
      "39                3.9               0.026316                     0.1   \n",
      "40                3.6              -0.076923                    -0.3   \n",
      "41                3.6               0.000000                     0.0   \n",
      "42                3.6               0.000000                     0.0   \n",
      "43                3.8               0.055556                     0.2   \n",
      "44               13.0               2.421053                     9.2   \n",
      "45                8.8              -0.323077                    -4.2   \n",
      "46                6.8              -0.227273                    -2.0   \n",
      "47                6.2              -0.088235                    -0.6   \n",
      "48                5.9              -0.048387                    -0.3   \n",
      "49                5.1              -0.135593                    -0.8   \n",
      "50                4.2              -0.176471                    -0.9   \n",
      "51                3.8              -0.095238                    -0.4   \n",
      "52                3.6              -0.052632                    -0.2   \n",
      "53                3.6               0.000000                     0.0   \n",
      "54                3.6               0.000000                     0.0   \n",
      "\n",
      "    House Price Index (Level)  House Price Index (Level)_QoQ  \\\n",
      "0                       139.2                            NaN   \n",
      "1                       139.7                       0.003592   \n",
      "2                       140.2                       0.003579   \n",
      "3                       140.2                       0.000000   \n",
      "4                       139.3                      -0.006419   \n",
      "5                       136.7                      -0.018665   \n",
      "6                       135.4                      -0.009510   \n",
      "7                       134.1                      -0.009601   \n",
      "8                       133.7                      -0.002983   \n",
      "9                       134.3                       0.004488   \n",
      "10                      134.3                       0.000000   \n",
      "11                      135.8                       0.011169   \n",
      "12                      139.0                       0.023564   \n",
      "13                      141.7                       0.019424   \n",
      "14                      144.7                       0.021171   \n",
      "15                      148.4                       0.025570   \n",
      "16                      152.4                       0.026954   \n",
      "17                      156.1                       0.024278   \n",
      "18                      159.2                       0.019859   \n",
      "19                      161.2                       0.012563   \n",
      "20                      162.3                       0.006824   \n",
      "21                      164.4                       0.012939   \n",
      "22                      167.0                       0.015815   \n",
      "23                      169.0                       0.011976   \n",
      "24                      171.0                       0.011834   \n",
      "25                      173.5                       0.014620   \n",
      "26                      175.9                       0.013833   \n",
      "27                      178.1                       0.012507   \n",
      "28                      180.1                       0.011230   \n",
      "29                      182.6                       0.013881   \n",
      "30                      185.5                       0.015882   \n",
      "31                      188.0                       0.013477   \n",
      "32                      190.6                       0.013830   \n",
      "33                      193.6                       0.015740   \n",
      "34                      196.7                       0.016012   \n",
      "35                      199.7                       0.015252   \n",
      "36                      202.0                       0.011517   \n",
      "37                      204.0                       0.009901   \n",
      "38                      205.9                       0.009314   \n",
      "39                      207.5                       0.007771   \n",
      "40                      209.5                       0.009639   \n",
      "41                      211.9                       0.011456   \n",
      "42                      215.2                       0.015573   \n",
      "43                      217.8                       0.012082   \n",
      "44                      219.9                       0.009642   \n",
      "45                      226.9                       0.031833   \n",
      "46                      235.3                       0.037021   \n",
      "47                      243.0                       0.032724   \n",
      "48                      254.6                       0.047737   \n",
      "49                      266.3                       0.045954   \n",
      "50                      277.3                       0.041307   \n",
      "51                      290.3                       0.046881   \n",
      "52                      297.5                       0.024802   \n",
      "53                      297.6                       0.000336   \n",
      "54                      299.8                       0.007392   \n",
      "\n",
      "    House Price Index (Level)_diff  \n",
      "0                              NaN  \n",
      "1                              0.5  \n",
      "2                              0.5  \n",
      "3                              0.0  \n",
      "4                             -0.9  \n",
      "5                             -2.6  \n",
      "6                             -1.3  \n",
      "7                             -1.3  \n",
      "8                             -0.4  \n",
      "9                              0.6  \n",
      "10                             0.0  \n",
      "11                             1.5  \n",
      "12                             3.2  \n",
      "13                             2.7  \n",
      "14                             3.0  \n",
      "15                             3.7  \n",
      "16                             4.0  \n",
      "17                             3.7  \n",
      "18                             3.1  \n",
      "19                             2.0  \n",
      "20                             1.1  \n",
      "21                             2.1  \n",
      "22                             2.6  \n",
      "23                             2.0  \n",
      "24                             2.0  \n",
      "25                             2.5  \n",
      "26                             2.4  \n",
      "27                             2.2  \n",
      "28                             2.0  \n",
      "29                             2.5  \n",
      "30                             2.9  \n",
      "31                             2.5  \n",
      "32                             2.6  \n",
      "33                             3.0  \n",
      "34                             3.1  \n",
      "35                             3.0  \n",
      "36                             2.3  \n",
      "37                             2.0  \n",
      "38                             1.9  \n",
      "39                             1.6  \n",
      "40                             2.0  \n",
      "41                             2.4  \n",
      "42                             3.3  \n",
      "43                             2.6  \n",
      "44                             2.1  \n",
      "45                             7.0  \n",
      "46                             8.4  \n",
      "47                             7.7  \n",
      "48                            11.6  \n",
      "49                            11.7  \n",
      "50                            11.0  \n",
      "51                            13.0  \n",
      "52                             7.2  \n",
      "53                             0.1  \n",
      "54                             2.2  \n",
      "House Price Index (Level)_diff is insignificant and dropped from the backward selection: p-value 0.897581705982097\n",
      "House Price Index (Level)_QoQ_lag is insignificant and dropped from the backward selection: p-value 0.8957862669036145\n",
      "Unemployment rate is insignificant and dropped from the backward selection: p-value 0.8770640900470119\n",
      "House Price Index (Level) is insignificant and dropped from the backward selection: p-value 0.3017712833987057\n",
      "Unemployment rate_diff is insignificant and dropped from the backward selection: p-value 0.22055491733264104\n",
      "Unemployment rate_diff_lag is insignificant and dropped from the backward selection: p-value 0.5253326547676781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vb11161\\AppData\\Local\\Temp/ipykernel_24920/1261928435.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exog_trans[x+'_QoQ'] =  exog_trans[x]/exog_trans[x].shift()-1\n",
      "C:\\Users\\vb11161\\AppData\\Local\\Temp/ipykernel_24920/1261928435.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exog_trans[x+'_diff'] = exog_trans[x]-exog_trans[x].shift()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>30Y10Y_MBSOAS_TY</td> <th>  R-squared:         </th> <td>   0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   13.21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 29 Aug 2023</td> <th>  Prob (F-statistic):</th> <td>3.07e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:15:39</td>     <th>  Log-Likelihood:    </th> <td> -191.62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    48</td>      <th>  AIC:               </th> <td>   389.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   394.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                         <td>   27.2952</td> <td>    3.365</td> <td>    8.112</td> <td> 0.000</td> <td>   20.518</td> <td>   34.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Unemployment rate_QoQ</th>         <td>  -18.2976</td> <td>    5.557</td> <td>   -3.293</td> <td> 0.002</td> <td>  -29.490</td> <td>   -7.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>House Price Index (Level)_QoQ</th> <td> -728.9489</td> <td>  162.853</td> <td>   -4.476</td> <td> 0.000</td> <td>-1056.951</td> <td> -400.946</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.030</td> <th>  Durbin-Watson:     </th> <td>   1.624</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.049</td> <th>  Jarque-Bera (JB):  </th> <td>   7.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.294</td> <th>  Prob(JB):          </th> <td>  0.0245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.834</td> <th>  Cond. No.          </th> <td>    83.4</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       30Y10Y_MBSOAS_TY   R-squared:                       0.370\n",
       "Model:                            OLS   Adj. R-squared:                  0.342\n",
       "Method:                 Least Squares   F-statistic:                     13.21\n",
       "Date:                Tue, 29 Aug 2023   Prob (F-statistic):           3.07e-05\n",
       "Time:                        11:15:39   Log-Likelihood:                -191.62\n",
       "No. Observations:                  48   AIC:                             389.2\n",
       "Df Residuals:                      45   BIC:                             394.8\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "const                            27.2952      3.365      8.112      0.000      20.518      34.072\n",
       "Unemployment rate_QoQ           -18.2976      5.557     -3.293      0.002     -29.490      -7.105\n",
       "House Price Index (Level)_QoQ  -728.9489    162.853     -4.476      0.000   -1056.951    -400.946\n",
       "==============================================================================\n",
       "Omnibus:                        6.030   Durbin-Watson:                   1.624\n",
       "Prob(Omnibus):                  0.049   Jarque-Bera (JB):                7.418\n",
       "Skew:                           0.294   Prob(JB):                       0.0245\n",
       "Kurtosis:                       4.834   Cond. No.                         83.4\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the Dependent & Independent Variables# \n",
    "Variable_Name ='30Y10Y_MBSOAS_TY'\n",
    "Variable_ID = '30Y10Y_MBSOAS_TY_diff'\n",
    "\n",
    "Parm1 ='Unemployment rate' \n",
    "Parm2='House Price Index (Level)'\n",
    "\n",
    "VM1_list =[Variable_Name,Parm1,Parm2]\n",
    "VM1 =Hist_Data\n",
    "#print(Hist_Data)\n",
    "\n",
    "Parm1_ind='Unemployment rate_diff'  \n",
    "Parm1_ind_lag='Unemployment rate_diff_lag' \n",
    "Parm2_ind='House Price Index (Level)_QoQ'\n",
    "Parm2_ind_lag='House Price Index (Level)_QoQ_lag'\n",
    "\n",
    "#Clean and Transform Data# \n",
    "VM1_Tran=fcst_data_prep(VM1_list,['QoQ','diff'], VM1, '7/1/2009', '1/1/2023')\n",
    "\n",
    "print(VM1_Tran)\n",
    "\n",
    "VM1_Tran=VM1_Tran.dropna()\n",
    "\n",
    "VM1_Tran[Parm1_ind_lag]=VM1_Tran[Parm1_ind].shift()\n",
    "VM1_Tran[Parm2_ind_lag]=VM1_Tran[Parm2_ind].shift()\n",
    "\n",
    "#Run Backward selection \n",
    "Full_Sample_Data = VM1_Tran.drop(['month'], axis=1).dropna()\n",
    "Full_Sample_Data = Full_Sample_Data.drop(['30Y10Y_MBSOAS_TY_diff','30Y10Y_MBSOAS_TY_QoQ'], axis=1)\n",
    "\n",
    "T=backward_regression(Full_Sample_Data, Variable_Name)\n",
    "    \n",
    "T.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd2f125",
   "metadata": {},
   "source": [
    "#RUN FINAL MODELS# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5938905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vb11161\\AppData\\Local\\Temp/ipykernel_24920/1261928435.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exog_trans[x+'_QoQ'] =  exog_trans[x]/exog_trans[x].shift()-1\n",
      "C:\\Users\\vb11161\\AppData\\Local\\Temp/ipykernel_24920/1261928435.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exog_trans[x+'_diff'] = exog_trans[x]-exog_trans[x].shift()\n",
      "C:\\Users\\vb11161\\AppData\\Local\\conda\\conda\\envs\\py39\\lib\\site-packages\\statsmodels\\tsa\\stattools.py:2015: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\vb11161\\AppData\\Local\\conda\\conda\\envs\\py39\\lib\\site-packages\\statsmodels\\tsa\\stattools.py:2015: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\vb11161\\AppData\\Local\\conda\\conda\\envs\\py39\\lib\\site-packages\\statsmodels\\tsa\\stattools.py:2015: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\vb11161\\AppData\\Local\\conda\\conda\\envs\\py39\\lib\\site-packages\\statsmodels\\tsa\\stattools.py:2015: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\vb11161\\AppData\\Local\\conda\\conda\\envs\\py39\\lib\\site-packages\\statsmodels\\graphics\\tsaplots.py:348: FutureWarning: The default method 'yw' can produce PACF values outside of the [-1,1] interval. After 0.13, the default will change tounadjusted Yule-Walker ('ywm'). You can use this method now by setting method='ywm'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['30Y10Y_MBSOAS_TY'] ADF Result: The series is stationary\n",
      "['30Y10Y_MBSOAS_TY'] ADF Result: The series is stationary\n",
      "['30Y10Y_MBSOAS_TY'] ADF Result: The series is stationary\n",
      "['30Y10Y_MBSOAS_TY'] KPSS Result: The series is stationary\n",
      "['30Y10Y_MBSOAS_TY'] KPSS Result: The series is stationary\n",
      "['30Y10Y_MBSOAS_TY'] KPSS Result: The series is stationary\n",
      "['30Y10Y_MBSOAS_TY'] KPSS Result: The series is stationary\n",
      "['30Y10Y_MBSOAS_TY'] ADF Result: The series is stationary\n",
      "['30Y10Y_MBSOAS_TY'] ADF Result: The series is stationary\n",
      "['30Y10Y_MBSOAS_TY'] ADF Result: The series is stationary\n",
      "['30Y10Y_MBSOAS_TY'] KPSS Result: The series is stationary\n",
      "['30Y10Y_MBSOAS_TY'] KPSS Result: The series is stationary\n",
      "['30Y10Y_MBSOAS_TY'] KPSS Result: The series is stationary\n",
      "['30Y10Y_MBSOAS_TY'] KPSS Result: The series is stationary\n",
      "Unemployment rate_diff_lag ADF Result: The series is stationary\n",
      "Unemployment rate_diff_lag ADF Result: The series is stationary\n",
      "Unemployment rate_diff_lag ADF Result: The series is stationary\n",
      "Unemployment rate_diff_lag KPSS Result: The series is stationary\n",
      "Unemployment rate_diff_lag KPSS Result: The series is stationary\n",
      "Unemployment rate_diff_lag KPSS Result: The series is stationary\n",
      "Unemployment rate_diff_lag KPSS Result: The series is stationary\n",
      "House Price Index (Level)_QoQ ADF Result: The series is stationary\n",
      "House Price Index (Level)_QoQ ADF Result: The series is stationary\n",
      "House Price Index (Level)_QoQ ADF Result: The series is stationary\n",
      "House Price Index (Level)_QoQ KPSS Result: The series is stationary\n",
      "House Price Index (Level)_QoQ KPSS Result: The series is stationary\n",
      "House Price Index (Level)_QoQ KPSS Result: The series is stationary\n",
      "House Price Index (Level)_QoQ KPSS Result: The series is stationary\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       30Y10Y_MBSOAS_TY   R-squared:                       0.215\n",
      "Model:                            OLS   Adj. R-squared:                  0.181\n",
      "Method:                 Least Squares   F-statistic:                     10.82\n",
      "Date:                Tue, 29 Aug 2023   Prob (F-statistic):           0.000141\n",
      "Time:                        11:35:28   Log-Likelihood:                -200.51\n",
      "No. Observations:                  49   AIC:                             407.0\n",
      "Df Residuals:                      46   BIC:                             412.7\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:                  HAC                                         \n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "const                            24.5829      2.154     11.411      0.000      20.361      28.805\n",
      "Unemployment rate_diff_lag        1.0185      0.338      3.011      0.003       0.356       1.681\n",
      "House Price Index (Level)_QoQ  -583.2731    125.693     -4.640      0.000    -829.626    -336.920\n",
      "==============================================================================\n",
      "Omnibus:                        6.078   Durbin-Watson:                   1.736\n",
      "Prob(Omnibus):                  0.048   Jarque-Bera (JB):                7.688\n",
      "Skew:                          -0.280   Prob(JB):                       0.0214\n",
      "Kurtosis:                       4.858   Cond. No.                         119.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 10 lags and without small sample correction\n",
      "const                            2.653002\n",
      "Unemployment rate_diff_lag       1.001455\n",
      "House Price Index (Level)_QoQ    1.001455\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vb11161\\AppData\\Local\\Temp/ipykernel_24920/2645496651.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hist_data_OutofSample['level_prediction_full'] = untransformation(hist_data_OutofSample['prediction'],hist_data_OutofSample,dependent_var_level,tran_type)\n",
      "C:\\Users\\vb11161\\AppData\\Local\\Temp/ipykernel_24920/2645496651.py:151: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  backtest_transformed_prediction['MS_RMSE_N']=MS_RMSE_N\n",
      "C:\\Users\\vb11161\\AppData\\Local\\Temp/ipykernel_24920/2645496651.py:152: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  backtest_transformed_prediction['MS_MAPE']=MS_MAPE\n",
      "C:\\Users\\vb11161\\AppData\\Local\\Temp/ipykernel_24920/1261928435.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exog_trans[x+'_QoQ'] =  exog_trans[x]/exog_trans[x].shift()-1\n",
      "C:\\Users\\vb11161\\AppData\\Local\\Temp/ipykernel_24920/1261928435.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exog_trans[x+'_diff'] = exog_trans[x]-exog_trans[x].shift()\n",
      "C:\\Users\\vb11161\\AppData\\Local\\conda\\conda\\envs\\py39\\lib\\site-packages\\xlsxwriter\\worksheet.py:1439: UserWarning: Image file 'Backtesting_30Y10Y_MBSOAS_TY.png' not found.\n",
      "  warn(\"Image file '%s' not found.\" % filename)\n",
      "C:\\Users\\vb11161\\AppData\\Local\\conda\\conda\\envs\\py39\\lib\\site-packages\\xlsxwriter\\workbook.py:339: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the Dependent & Independent Variables# \n",
    "\n",
    "#OtherSpread 30Y3M_MBSOAS_TY\n",
    "\n",
    "Variable_Name ='30Y10Y_MBSOAS_TY'\n",
    "Variable_ID ='30Y10Y_MBSOAS_TY_diff'\n",
    "\n",
    "Parm1 ='Unemployment rate' \n",
    "Parm2='House Price Index (Level)'\n",
    "\n",
    "\n",
    "#Several Parms can be used.  Must add it into the list and functions below\n",
    "type = 'OLS_HAC'\n",
    "tran_type ='level'\n",
    "order= None\n",
    "\n",
    "## the below paramters are used to determine if the level or the transformation is used in the model. Set the var_tran to level\n",
    "dependent_var = f'{Variable_Name}'\n",
    "dependent_var_tran  = f'{Variable_Name}'\n",
    "\n",
    "Parm1_ind='Unemployment rate_diff'  \n",
    "Parm1_ind_lag='Unemployment rate_diff_lag' \n",
    "Parm1_ind_lag2='Unemployment rate_diff_lag2' \n",
    "Parm2_ind='House Price Index (Level)_QoQ'\n",
    "Parm2_ind_lag='House Price Index (Level)_QoQ_lag'\n",
    "Parm2_ind_lag2='House Price Index (Level)_QoQ_lag2'\n",
    "\n",
    "\n",
    "#MODEL INPUTES#\n",
    "\n",
    "Independent=[Parm1_ind_lag,Parm2_ind]\n",
    "pdf = f'{dependent_var}.png'\n",
    "\n",
    "#Set the transformation of Dependent & Independent Variables names#\n",
    "\n",
    "#Pull Actuals For the Data Transformation Process\n",
    "VM1_list =[Variable_Name,Parm1,Parm2]\n",
    "VM1 =Hist_Data\n",
    "\n",
    "VM1_Tran=fcst_data_prep(VM1_list,['QoQ','diff'], VM1, '7/1/2009', '1/1/2022')\n",
    "\n",
    "#VAdditional Transformation - Add lags and remove NAs\n",
    "\n",
    "VM1_Tran[Parm1_ind_lag]=VM1_Tran[Parm1_ind].shift()\n",
    "VM1_Tran[Parm1_ind_lag2]=VM1_Tran[Parm1_ind].shift(2)\n",
    "VM1_Tran[Parm2_ind_lag]=VM1_Tran[Parm2_ind].shift()\n",
    "VM1_Tran[Parm2_ind_lag2]=VM1_Tran[Parm2_ind].shift(2)\n",
    "\n",
    "VM1_Tran=VM1_Tran.dropna()\n",
    "\n",
    "#Test for Stationrity of All Variables\n",
    "\n",
    "test_stationary([dependent_var], VM1_Tran[dependent_var], 'ADF', backtest= None)\n",
    "test_stationary([dependent_var], VM1_Tran[dependent_var], 'KPSS', backtest= None)\n",
    "\n",
    "test_stationary([dependent_var_tran], VM1_Tran[dependent_var_tran], 'ADF', backtest= None)\n",
    "test_stationary([dependent_var_tran], VM1_Tran[dependent_var_tran], 'KPSS', backtest= None)\n",
    "\n",
    "######################################DO NOT TOUCH THE CODE BELOW##############################\n",
    "\n",
    "#Full Model Parameters # \n",
    "Model_Fit, VIF, Stationary_ADF1 , Stationary_KPSS1 = fit(VM1_Tran,type,Independent,dependent_var_tran,order=None)\n",
    "out = Model_Fit.summary() \n",
    "\n",
    "Model_DA=model_diagnostic(Model_Fit,type)\n",
    "print(out)\n",
    "print(VIF)\n",
    "\n",
    "residual_plot(Model_Fit, dependent_var_tran, pdf)\n",
    "\n",
    "#Backtesting Parameters - This is setup to remove 9QRTs from the prior estimation dataset. \n",
    "Insample_parm, Insample_perform, backtest_untransformed_prediction, backtest_transformed_prediction = backtesting_plot(VM1_Tran, type, Independent, dependent_var,dependent_var_tran, pdf, 9,tran_type, order, Special_transformation=False)\n",
    "\n",
    "#print(backtest_transformed_prediction)\n",
    "\n",
    "#pull the scenario forecast from the library.  This will need to be updated with a CSV file. \n",
    "#dt_base =scenario.get_data(variables= VM_list_Base) # Pull the scenario forecast from the library. This will need to be replaced with a pull from CSV\n",
    "Scenario_Base =fcst_data_prep(VM1_list,['level','QoQ','diff'],dt_base, '1/1/2023', '4/1/2026')\n",
    "\n",
    "#dt_stress =scenario.get_data(variables= VM_list_Stress) # Pull the scenario forecast from the library. This will need to be replaced with a pull from CSV\n",
    "Scenario_Stress =fcst_data_prep(VM1_list,['level','QoQ','diff'],dt_stress, '1/1/2023', '4/1/2026')\n",
    "\n",
    "######################################DO NOT TOUCH THE CODE ABOVE ##############################\n",
    "#Additional transformation on scenario forecasts \n",
    "\n",
    "#Scenario_Base=Scenario_Base.dropna()\n",
    "\n",
    "#VAdditional Transformation - Add lags and remove NAs\n",
    "\n",
    "Scenario_Base[Parm1_ind_lag]=Scenario_Base[Parm1_ind].shift()\n",
    "Scenario_Base[Parm2_ind_lag]=Scenario_Base[Parm2_ind].shift()\n",
    "\n",
    "#Scenario_Stress=Scenario_Stress.dropna()\n",
    "\n",
    "Scenario_Stress[Parm1_ind_lag]=Scenario_Stress[Parm1_ind].shift()\n",
    "Scenario_Stress[Parm2_ind_lag]=Scenario_Stress[Parm2_ind].shift()\n",
    "\n",
    "######################################DO NOT TOUCH THE CODE BELOW ##############################\n",
    "\n",
    "#Scenario forecast function \n",
    "scenario_base_data,scenario_stress_data =scenario_output(Model_Fit, Scenario_Base, Scenario_Stress,Independent,dependent_var,pdf, type, tran_type)\n",
    "\n",
    "#Output Fullsample and Backtesting data Summary# \n",
    "Full_Estimation_Data = VM1_Tran[['month',dependent_var_tran ,Parm1_ind,Parm2_ind]]\n",
    "Backtesting_Data =  VM1_Tran[:-9]\n",
    "Backtesting_Estimation_Data = Backtesting_Data[['month',dependent_var_tran ,Parm1_ind,Parm2_ind]]\n",
    "\n",
    "#print(out)\n",
    "#Print out Results to Excel Workbooks \n",
    "excel_output(out,Model_DA,VIF,Insample_parm, Stationary_ADF1 , Stationary_KPSS1,Full_Estimation_Data,Backtesting_Estimation_Data, Variable_Name,backtest_untransformed_prediction, backtest_transformed_prediction,scenario_base_data,scenario_stress_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
